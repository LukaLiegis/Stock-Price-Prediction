{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMZdmqQGuUL5XGQggyA7vYM",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LukaLiegis/Stock-Price-Prediction/blob/main/TimeSeriesForecasting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Importing and Downloading Libraries"
      ],
      "metadata": {
        "id": "JRjoGAnyf1V5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pandas_ta &> /dev/null\n",
        "!pip install yfinance &> /dev/null\n",
        "!pip install tensorflow_addons &> /dev/null"
      ],
      "metadata": {
        "id": "an3_aqr3f07Y"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fAt0yND-fG37"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import yfinance as yf\n",
        "import tensorflow as tf\n",
        "import pandas_ta as ta"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Getting Data"
      ],
      "metadata": {
        "id": "10FU7w-hf6Fb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = yf.download(\"MSFT\", period=\"max\")\n",
        "dataset = (data.drop(columns=['Adj Close']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2j9sx6-f6UA",
        "outputId": "d8bb6230-19cc-4583-fc2c-786cba7bfdb2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r[*********************100%***********************]  1 of 1 completed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Technical Indicators\n",
        "\n",
        "Here I use mostly all of the indicators that Pandas_TA lets me."
      ],
      "metadata": {
        "id": "DR8kIWE8fWJC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_technical_indicators(dataset):\n",
        "    # Create 7 and 21 days Moving Average\n",
        "    dataset['ma7'] = dataset['Close'].rolling(window=7).mean()\n",
        "    dataset['ma21'] = dataset['Close'].rolling(window=21).mean()\n",
        "    dataset['ma100'] = dataset['Close'].rolling(window=100).mean()\n",
        "    dataset['ma150'] = dataset['Close'].rolling(window=150).mean()\n",
        "    dataset['ma200'] = dataset['Close'].rolling(window=200).mean()\n",
        "    \n",
        "    # Create Exponential moving average\n",
        "    dataset[\"ema30\"] = dataset.ta.ema(30)\n",
        "    dataset['ema200'] = dataset.ta.ema(200)\n",
        "\n",
        "    #Logarithmic Return\n",
        "    dataset[\"Log_Data\"] = (np.log(dataset[\"Close\"]))\n",
        "\n",
        "    #\n",
        "    dataset[\"ebsw\"] = dataset.ta.ebsw()\n",
        "    \n",
        "    #Other Pandas-TA Indicators\n",
        "    dataset[\"RSI\"] = dataset.ta.rsi()\n",
        "    dataset[\"RSX\"] = dataset.ta.rsx()\n",
        "    dataset[\"uo\"] = dataset.ta.uo()\n",
        "    \n",
        "    #Pandas-TA Statistics\n",
        "    dataset[\"entropy\"] = dataset.ta.entropy()\n",
        "    dataset[\"kurtosis\"] = dataset.ta.kurtosis()\n",
        "    dataset[\"mad\"] = dataset.ta.mad()\n",
        "    dataset[\"median\"] = dataset.ta.median()\n",
        "    dataset[\"quantile\"] = dataset.ta.quantile()\n",
        "    dataset[\"skew\"] = dataset.ta.skew()\n",
        "    dataset[\"stdev\"] = dataset.ta.stdev()\n",
        "    dataset[\"variance\"] = dataset.ta.variance()\n",
        "    dataset[\"zscore\"] = dataset.ta.zscore()\n",
        "\n",
        "    #Pandas-TA Trend\n",
        "    dataset[\"chop\"] = dataset.ta.chop()\n",
        "    dataset[\"decay\"] = dataset.ta.decay()\n",
        "    dataset[\"decreasing\"] = dataset.ta.decreasing()\n",
        "    dataset[\"dpo\"] = dataset.ta.dpo()\n",
        "    dataset[\"increasing\"] = dataset.ta.increasing()\n",
        "    dataset[\"qstick\"] = dataset.ta.qstick()\n",
        "\n",
        "    #Pandas-TA Volatility\n",
        "    dataset[\"massi\"] = dataset.ta.massi()\n",
        "\n",
        "    #Pandas-TA Volume\n",
        "    dataset[\"ad\"] = dataset.ta.ad()\n",
        "    \n",
        "    return dataset"
      ],
      "metadata": {
        "id": "XG1oHjKmfVD5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_TI = get_technical_indicators(dataset)\n",
        "dataset_TI = dataset_TI.dropna()"
      ],
      "metadata": {
        "id": "36fXCq-BfhSf"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#dataset_TI"
      ],
      "metadata": {
        "id": "Nk-fBM4nh1ER"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Feature Engineering"
      ],
      "metadata": {
        "id": "gMIGAM3zflFT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Total dataset has {} samples, and {} features.'.format(dataset_TI.shape[0], \\\n",
        "                                                              dataset_TI.shape[1]))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADfFkjLCwL74",
        "outputId": "4779e18e-ae40-45c2-a424-96bfe4d838d8"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total dataset has 9061 samples, and 34 features.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#####Scaling Data"
      ],
      "metadata": {
        "id": "KbI8hS7cwMg_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "names = dataset_TI.columns\n",
        "d = scaler.fit_transform(dataset_TI)\n",
        "scaled_df = pd.DataFrame(d, columns=names)\n",
        "scaled_df"
      ],
      "metadata": {
        "id": "Yj3oU_pbqtGH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y = scaled_df.iloc[:, 3:4]\n",
        "X = scaled_df.drop(scaled_df.iloc[:, 3:4],axis = 1)"
      ],
      "metadata": {
        "id": "Kfpg-WYRugYT"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XLpopsjOxCBe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#column_indices = {name: i for i, name in enumerate(scaled_df.columns)}\n",
        "\n",
        "n = len(scaled_df)\n",
        "#70% of the data is used for training.\n",
        "X_train_df = X[0:int(n*0.7)]\n",
        "y_train_df = y[0:int(n*0.7)]\n",
        "#20% of the data is used for validation.\n",
        "X_val_df = X[int(n*0.7):int(n*0.9)]\n",
        "y_val_df = y[int(n*0.7):int(n*0.9)]\n",
        "#10% of the data is being used for testing.\n",
        "X_test_df = X[int(n*0.9):]\n",
        "y_test_df = y[int(n*0.9):]\n",
        "\n",
        "num_features = scaled_df.shape[1]"
      ],
      "metadata": {
        "id": "SUzR3E5iiUQ0"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Extracting high-level features with Stacked Autoencoders"
      ],
      "metadata": {
        "id": "0lJankbfrho3"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T9e68eGDsGp9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Model"
      ],
      "metadata": {
        "id": "_jUjOaGKzqn9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#creating stacked model\n",
        "model=Sequential()\n",
        "model.add(GRU(16,return_sequences=True,input_shape=(X_train.shape[1],X_train.shape[2])))\n",
        "model.add(PReLU())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(GRU(4,return_sequences=False))\n",
        "model.add(PReLU())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "model.add(Dense(1))\n",
        "model.add(PReLU())\n",
        "model.compile(loss=\"huber\", metrics=[\"mse\", 'mape'],optimizer='adam')"
      ],
      "metadata": {
        "id": "GDfyvbFrzrzZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}